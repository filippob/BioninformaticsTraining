{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-TykfLxN6_L"
      },
      "source": [
        "# Dog breeds identification\n",
        "\n",
        "Multi-class classification problem, we are asked to identify dog breeds from images of dogs.\n",
        "The dataset comprises 120 breeds of dogs.\n",
        "\n",
        "The dataset is deposited [here](https://www.kaggle.com/competitions/dog-breed-identification).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "066Hk1V5_AP2"
      },
      "source": [
        "# Config\n",
        "\n",
        "#### Python libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## SYSTEM LIBRARIES\n",
        "import glob     #for checking dir content\n",
        "import os       #for dir creation\n",
        "import requests #for data download\n",
        "import zipfile  #for unpacking zipped files\n",
        "\n",
        "## DATA SCIENCE AND PREPROCESSING LIBRARIES\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## TENSORFLOW AND KERAS\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.layers import Dropout\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ],
      "metadata": {
        "id": "vC-jdeUXG8e-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Support functions"
      ],
      "metadata": {
        "id": "oWFvMDRNH8aL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## function to plot loos and accuracy over epochs\n",
        "def plot_loss_history(h, title):\n",
        "  for metric in h.history.keys():\n",
        "    #ignoring metrics on validation set, which are implied when\n",
        "    #plotting on training set\n",
        "    if metric.startswith('val_'):\n",
        "      continue\n",
        "    \n",
        "    #if we get here we found a metric on the training set,\n",
        "    #let's plot it\n",
        "    plt.plot(h.history[metric], label = \"Train set\")\n",
        "    plt.plot(h.history[\"val_\" + metric], label = \"Validation set\")\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.title(title + ' - ' + metric)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "XLPQ1YjtH7t6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Parameters"
      ],
      "metadata": {
        "id": "AyUmTioVIEPp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiaFDmq3-2qq"
      },
      "source": [
        "#where the data are stored\n",
        "#data_url = 'http://www.jackdellequerce.com/data/reduced_chest_xray.zip'\n",
        "#data_url = 'https://cloud.cnr.it/owncloud/index.php/s/TU2f6k6gMOiPHci'\n",
        "data_url = 'http://www.jackdellequerce.com/data/dogs/reduced.zip'\n",
        "#where to place the data\n",
        "download_target_imgs = '/content/data/'\n",
        "base_dir = download_target_imgs + 'reduced/'\n",
        "\n",
        "#Keras constants\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = [180, 180]\n",
        "IMAGE_SHAPE = (IMAGE_SIZE[0], IMAGE_SIZE[1])\n",
        "INPUT_SHAPE = (IMAGE_SIZE[0], IMAGE_SIZE[1], 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting the data\n",
        "\n",
        "The data are first downloaded as a zipped archive, which is then uncompressed and stored in `download_target_imgs` (the zipped archive has an internal structure with root `reduced/`)"
      ],
      "metadata": {
        "id": "ZAq6ZOmMIH5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!rm -r /content/data/reduced/train"
      ],
      "metadata": {
        "id": "VfFjySLKU6-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#room for data\n",
        "os.makedirs(download_target_imgs, exist_ok=True)\n",
        "\n",
        "#downloading\n",
        "r = requests.get(data_url)\n",
        "open(download_target_imgs + 'local_archive.zip', 'wb').write(r.content)"
      ],
      "metadata": {
        "id": "oDbs5YKuEKcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unpacking\n",
        "z = zipfile.ZipFile(download_target_imgs + 'local_archive.zip')\n",
        "z.extractall(path = download_target_imgs)"
      ],
      "metadata": {
        "id": "xmHvCpE1GQRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have two subfolders:\n",
        "- one contains images for training\n",
        "- one contains test images"
      ],
      "metadata": {
        "id": "pIMKmWXS_i8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#at this point data is there, we are ready to get the list of files\n",
        "train_filenames = glob.glob(base_dir + 'train/*')\n",
        "test_filenames   = glob.glob(base_dir + 'test/*')\n",
        "\n",
        "#whatever the original case, at this point we have the files\n",
        "print('Available images for train: ' + str(len(train_filenames)))\n",
        "print('Available images for test: ' + str(len(test_filenames)))"
      ],
      "metadata": {
        "id": "62ReSLtuXeAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reading labels\n",
        "\n",
        "We now read in a `.csv` file with labels (breed name) corresponding to each image in the training set:"
      ],
      "metadata": {
        "id": "-RyHnvm0_zfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_df = pd.read_csv(base_dir + 'labels_reduced.csv')\n",
        "print('Training set: {}'.format(label_df.shape))"
      ],
      "metadata": {
        "id": "c_XCm1slRlMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_df"
      ],
      "metadata": {
        "id": "t920k7D8R458"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "String labels (\"words\") are converted to numbers (DNNs are matrix algebra machines: they understand numbers, not words!)"
      ],
      "metadata": {
        "id": "jQTArpUh__7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the breed into digits\n",
        "label_df['label'] = preprocessing.LabelEncoder().fit_transform(label_df.breed)\n",
        " \n",
        "# Create a breed-2-index dictionary\n",
        "dict_df = label_df[['label','breed']].copy()\n",
        "dict_df.drop_duplicates(inplace=True)\n",
        "dict_df.set_index('label',drop=True,inplace=True)\n",
        " \n",
        "index_to_breed = dict_df.to_dict()['breed']"
      ],
      "metadata": {
        "id": "SgAB0pjiRxxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_df"
      ],
      "metadata": {
        "id": "ur5igs1aSv9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have a little `Python dictionary` with the correspondance between numeric code and breed name:"
      ],
      "metadata": {
        "id": "dDaZSs4iANCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_breed"
      ],
      "metadata": {
        "id": "pzjVmyYPWWuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "#function to show bar length\n",
        "def barw(ax): \n",
        "    \n",
        "    for p in ax.patches:\n",
        "        val = p.get_width() #height of the bar\n",
        "        x = p.get_x()+ p.get_width() # x- position \n",
        "        y = p.get_y() + p.get_height()/2 #y-position\n",
        "        ax.annotate(round(val,2),(x,y))\n",
        "        \n",
        "#finding top dog brands\n",
        "\n",
        "plt.figure(figsize = (5,3))\n",
        "ax0 =sns.countplot(y=label_df['breed'],order=label_df['breed'].value_counts().index)\n",
        "barw(ax0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Fks0068TWXay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A little preprocessing here: \n",
        "- we convert numeric codes to OHE (one-hot encoded) vectors\n",
        "- we add the suffix `.jpg` to the image names (because the actual files do have this extension)"
      ],
      "metadata": {
        "id": "_3TirCChAb33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = label_df['label'].to_numpy().tolist()\n",
        "target = tf.keras.utils.to_categorical(target)"
      ],
      "metadata": {
        "id": "1YqTVXprgZv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = pd.DataFrame(target)\n",
        "target = target.join(label_df['id'])\n",
        "target['id'] = target['id'] + '.jpg'"
      ],
      "metadata": {
        "id": "spfBtePxZi0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#newcols = [str(x) for x in target.columns[:-1]]\n",
        "#newcols.append('id')\n",
        "#target.columns = newcols\n",
        "target"
      ],
      "metadata": {
        "id": "pIlAlAhwgAeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's have a look at one training image:"
      ],
      "metadata": {
        "id": "NcBliJmOTzOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets check one image\n",
        "from IPython.display import display, Image\n",
        "\n",
        "fname = os.path.join(base_dir, 'train', target['id'][0])\n",
        "Image(fname)"
      ],
      "metadata": {
        "id": "iupy1tQkTF1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ImageDataGenerator\n",
        "\n",
        "Here we do data augmentation on training and validation data:\n",
        "- image flipping\n",
        "- brightness adjustments\n",
        "- image rotation\n",
        "- shearing and zooming\n",
        "- height/width shifts\n",
        "- color channel shifts "
      ],
      "metadata": {
        "id": "UpC1P4D4h5Um"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colnames = [x for x in target.columns[:-1]]"
      ],
      "metadata": {
        "id": "O2rXijF-nr6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colnames"
      ],
      "metadata": {
        "id": "PBxtGa_Ghb0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#declare two objects\n",
        "train_datagen      = ImageDataGenerator(\n",
        "    rescale=1./255, \n",
        "    horizontal_flip=True, \n",
        "    vertical_flip=True, \n",
        "    brightness_range = [0.5, 1.5],\n",
        "    #shear_range=0.1,\n",
        "    zoom_range=0.2,\n",
        "    #height_shift_range=0.1,\n",
        "    channel_shift_range=0.4,\n",
        "    rotation_range=40)\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "UEt8OZVJX1CE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and validation sets\n",
        "\n",
        "Choose a number of samples to be actually used for training in a training/validation split scheme:"
      ],
      "metadata": {
        "id": "cKtzUwB-Y1lk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = target.sample(n=275)"
      ],
      "metadata": {
        "id": "LGRl6RAPrWQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set"
      ],
      "metadata": {
        "id": "O6acpSlvCp64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get validation images (those not used in training):"
      ],
      "metadata": {
        "id": "0lkwBpuiF1Iy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_all = target.merge(training_set['id'].drop_duplicates(), on=['id'], \n",
        "                   how='left', indicator=True)\n",
        "validation_set = df_all[df_all['_merge'] == 'left_only']"
      ],
      "metadata": {
        "id": "6y962XJpsCf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(validation_set)"
      ],
      "metadata": {
        "id": "Rlns-vV0Ct8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading data from the dataframe (image file names and OHE labels).\n",
        "If class_mode is set to “raw” it treats the data in the column or list of columns of the dataframe as raw target value (which means you should be sure that data in these columns must be of numerical datatypes), will be helpful if you’re building a model for regression task like predicting the angle from the images of steering wheel or building a model that needs to predict multiple values at the same time."
      ],
      "metadata": {
        "id": "9t85_NN6Gc-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "dataframe=training_set,\n",
        "directory=base_dir + 'train/',\n",
        "x_col=\"id\",\n",
        "y_col=colnames,\n",
        "batch_size=BATCH_SIZE,\n",
        "seed=42,\n",
        "shuffle=False,\n",
        "class_mode=\"raw\",\n",
        "target_size=IMAGE_SHAPE)"
      ],
      "metadata": {
        "id": "nFFeo0o8m0eZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_generator = validation_datagen.flow_from_dataframe(\n",
        "dataframe=validation_set,\n",
        "directory=base_dir + 'train/',\n",
        "x_col=\"id\",\n",
        "y_col=colnames,\n",
        "#y_col = 'classes',\n",
        "batch_size=6,\n",
        "seed=42,\n",
        "shuffle=False,\n",
        "class_mode=\"raw\",\n",
        "target_size=IMAGE_SHAPE)"
      ],
      "metadata": {
        "id": "UzNni6BIpQEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = train_generator.next()\n",
        "print(y[0:5])\n",
        "print(x[0].shape)\n",
        "#print(x[0])\n",
        "plt.imshow(x[5])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0EI5pI5MDrVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target.shape"
      ],
      "metadata": {
        "id": "hecF7nSHqLzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model building\n",
        "\n",
        "Now we are ready to build our DNN model.\n",
        "We do this by stacking multiple layers of \"neurons\" (nodes) one on top of the other.\n",
        "Basically, in this simple example we replicate the same substructure:\n",
        "- convolutional layer with varying number of nodes\n",
        "- max pooling layer to reduce the complexity\n",
        "- dropout layer for regularization"
      ],
      "metadata": {
        "id": "92rZlqBeGwLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NCLASSES = 4 ## n. of dog breeds to recognise\n",
        "EPOCHS = 50"
      ],
      "metadata": {
        "id": "8ReABQiwHmg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#let's declare an empty model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=16, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", input_shape=INPUT_SHAPE))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(NCLASSES, activation='softmax'))\n",
        "#model.add(Dense(units=5, activation='softmax')) #five classes classification problem\n",
        "######################"
      ],
      "metadata": {
        "id": "jC0au4GSp9ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "_5NqCfgqqV0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now compile the specified model and run it!"
      ],
      "metadata": {
        "id": "Ffk2mBrdKI50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model compile\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(learning_rate=5e-4),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "F7AnzcEcqX7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_log = model.fit(x=train_generator,\n",
        "                    validation_data=valid_generator,\n",
        "                    verbose=2,\n",
        "                    epochs=EPOCHS\n",
        ")"
      ],
      "metadata": {
        "id": "QWaKV6emX7Wn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_history(train_log, 'My model')"
      ],
      "metadata": {
        "id": "9L_lZLedGr9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model evaluation\n",
        "\n",
        "Let's first get the labels (breeds) in the validation set:"
      ],
      "metadata": {
        "id": "BtAGxL5BLhEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "obs = []\n",
        "for vec in valid_generator.labels:\n",
        "  obs.append(np.argmax(vec))"
      ],
      "metadata": {
        "id": "Ya1Cp6DHL6N-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obs = np.array(obs)"
      ],
      "metadata": {
        "id": "v2kvyVNI0KFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(obs, return_counts=True)\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "metadata": {
        "id": "7b9HFH9DLpqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction accuracy\n",
        "\n",
        "#### Accuracy in the training set"
      ],
      "metadata": {
        "id": "SDPvEZvqMynw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on training data\n",
        "train_accuracy = []\n",
        "\n",
        "for i in range(10):\n",
        "  print(\"iteration\",i)\n",
        "  train_generator.reset()\n",
        "  scores = model.evaluate(train_generator)\n",
        "  print(\"%s%s: %.2f%%\" % (\"evaluate \",model.metrics_names[1], scores[1]*100))\n",
        "  train_accuracy.append(scores[1])"
      ],
      "metadata": {
        "id": "O0EIQu-pM6Za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Average training accuracy\")\n",
        "np.mean(train_accuracy)"
      ],
      "metadata": {
        "id": "rgOy9uvQNU-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Accuracy in the validation set"
      ],
      "metadata": {
        "id": "UmqksWmENg94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on Validation data\n",
        "val_accuracy = []\n",
        "\n",
        "for i in range(1):\n",
        "  print(\"iteration\",i)\n",
        "  valid_generator.reset()\n",
        "  scores = model.evaluate(valid_generator)\n",
        "  print(\"%s%s: %.2f%%\" % (\"evaluate \",model.metrics_names[1], scores[1]*100))\n",
        "  val_accuracy.append(scores[1])"
      ],
      "metadata": {
        "id": "NsDIkkAZMhcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Average validation accuracy\")\n",
        "np.mean(val_accuracy)"
      ],
      "metadata": {
        "id": "fL8c9jjtMn08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictions"
      ],
      "metadata": {
        "id": "QLGYuu9NNn3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valid_generator.reset()\n",
        "pred = model.predict(valid_generator,\n",
        "verbose=0)\n",
        "\n",
        "pred[0:5]"
      ],
      "metadata": {
        "id": "8a1csEc3FRQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = []\n",
        "for i in range(1):\n",
        "  print(\"iteration\",i)\n",
        "  valid_generator.reset()\n",
        "  pred = model.predict(valid_generator,\n",
        "  verbose=0)\n",
        "  y_pred.append(np.argmax(pred, axis=1))"
      ],
      "metadata": {
        "id": "30a7oMGfFdtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "Ajeoi9t9OVHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Confusion matrix"
      ],
      "metadata": {
        "id": "vAfrLpehPIYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "appended_data = []\n",
        "for i in range(len(y_pred)):\n",
        "  conf_mat = confusion_matrix(obs, y_pred[i])\n",
        "  print(conf_mat)\n",
        "  appended_data.append(pd.DataFrame(conf_mat))"
      ],
      "metadata": {
        "id": "VhI6qH33G0vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm_conc = pd.concat(appended_data)\n",
        "\n",
        "final_cm = cm_conc.groupby(cm_conc.index).mean()\n",
        "print(final_cm)"
      ],
      "metadata": {
        "id": "hBYSMNOTOhoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat,\n",
        "                              display_labels= [x for x in reversed(index_to_breed.values())])"
      ],
      "metadata": {
        "id": "1D7rzhdr1pgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disp.plot()"
      ],
      "metadata": {
        "id": "nQMaozbb3BDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sn\n",
        "\n",
        "#figure = plt.figure(figsize=(8, 8))\n",
        "#sn.heatmap(conf_mat, annot=True,cmap=plt.cm.Blues)\n",
        "#plt.tight_layout()\n",
        "#plt.ylabel('True label')\n",
        "#plt.xlabel('Predicted label')\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "UtIHkXiV0mtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TEST DATA\n",
        "\n",
        "Now we test the final DNN model on the 29 test images from the `test/` folder:"
      ],
      "metadata": {
        "id": "eHv9qARX3USf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_test = pd.read_csv(base_dir + 'labels_test.csv')\n",
        "print('Test set: {}'.format(label_test.shape))\n",
        "\n",
        "# Encode the breed into digits\n",
        "label_test['label'] = preprocessing.LabelEncoder().fit_transform(label_test.breed)\n",
        " \n",
        "# Create a breed-2-index dictionary\n",
        "dict_df = label_test[['label','breed']].copy()\n",
        "dict_df.drop_duplicates(inplace=True)\n",
        "dict_df.set_index('label',drop=True,inplace=True)\n",
        " \n",
        "index_to_breed = dict_df.to_dict()['breed']"
      ],
      "metadata": {
        "id": "_pz0uV8h3WQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = label_test['label'].to_numpy().tolist()\n",
        "test = tf.keras.utils.to_categorical(test)"
      ],
      "metadata": {
        "id": "jpBp_GdO4AcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.DataFrame(test)\n",
        "test = test.join(label_test['id'])\n",
        "test['id'] = test['id'] + '.jpg'\n",
        "test"
      ],
      "metadata": {
        "id": "vQ1xPMxC4Ts4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colnames = [x for x in test.columns[:-1]]\n",
        "colnames"
      ],
      "metadata": {
        "id": "sscPUMeA4oGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "fAJQ96FX4jAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "dataframe=test,\n",
        "directory=base_dir + 'test/',\n",
        "x_col=\"id\",\n",
        "y_col=colnames,\n",
        "#y_col = 'classes',\n",
        "batch_size=1,\n",
        "seed=42,\n",
        "shuffle=False,\n",
        "class_mode=\"raw\",\n",
        "target_size=IMAGE_SHAPE)"
      ],
      "metadata": {
        "id": "IDHK09ZR402S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_breed"
      ],
      "metadata": {
        "id": "5FNDajKo54lS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = test_generator.next()\n",
        "print(index_to_breed[np.argmax(y[0])])\n",
        "plt.imshow(x[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "prwyGx-X-HPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator.reset()\n",
        "pred = model.predict_generator(test_generator,verbose=1)\n",
        "y_pred = np.argmax(pred, axis=1)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "6a0sY2MZ6dHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obs = []\n",
        "for vec in test_generator.labels:\n",
        "  obs.append(np.argmax(vec))\n",
        "obs = np.array(obs)"
      ],
      "metadata": {
        "id": "j-FbAXtk6wQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'obs' : obs, 'preds' : y_pred})\n",
        "df2 = df.replace({\"obs\": index_to_breed, \"preds\" : index_to_breed})\n",
        "df2"
      ],
      "metadata": {
        "id": "FJNZy6hJ6-6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_mat = confusion_matrix(obs, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat,\n",
        "                              display_labels= [x for x in reversed(index_to_breed.values())])\n",
        "disp.plot()"
      ],
      "metadata": {
        "id": "gkRCPVMY8aWN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}